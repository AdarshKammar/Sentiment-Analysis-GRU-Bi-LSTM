{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'f:/python3.13t.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Embedding, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\adars\\OneDrive\\Desktop\\ExcelR Assignment\\06\\Sentiment.csv\"  # Use a raw string (r\"\") or escape backslashes\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocessing\n",
    "df = df[['text', 'sentiment']]  # Keep only relevant columns\n",
    "df['sentiment'] = df['sentiment'].map({'Positive': 1, 'Negative': 0, 'Neutral':2}) # Map sentiment labels to numerical values. Added Neutral\n",
    "df = df.dropna()  # Remove rows with missing values\n",
    "\n",
    "# Prepare data for the model\n",
    "X = df['text']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\") # Adjust vocab size as needed\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Padding\n",
    "max_len = 100 # Adjust sequence length as needed\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the GRU model\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 64, input_length=max_len)) # Embedding layer\n",
    "model.add(GRU(64, return_sequences=True)) # GRU layer\n",
    "model.add(Dropout(0.2)) # Dropout for regularization\n",
    "model.add(GRU(32)) # Another GRU layer\n",
    "model.add(Dropout(0.2)) # Dropout for regularization\n",
    "model.add(Dense(3, activation='softmax')) # Output layer with softmax for multi-class classification. 3 outputs for Pos, Neg, Neutral\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # Use sparse_categorical_crossentropy for integer labels\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test)) # Adjust epochs and batch size\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1) # Get predicted labels\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, predicted_labels))\n",
    "cm = confusion_matrix(y_test, predicted_labels)\n",
    "print(cm)\n",
    "\n",
    "\n",
    "# Example of making predictions on new text:\n",
    "def predict_sentiment(text):\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post', truncating='post')\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    sentiment_labels = {0: \"Negative\", 1: \"Positive\", 2:\"Neutral\"} # Define label mapping\n",
    "    return sentiment_labels[predicted_label]\n",
    "\n",
    "new_text = \"This movie was absolutely fantastic!\"\n",
    "predicted_sentiment = predict_sentiment(new_text)\n",
    "print(f\"Predicted sentiment for '{new_text}': {predicted_sentiment}\")\n",
    "\n",
    "\n",
    "new_text = \"This movie was terrible and boring.\"\n",
    "predicted_sentiment = predict_sentiment(new_text)\n",
    "print(f\"Predicted sentiment for '{new_text}': {predicted_sentiment}\")\n",
    "\n",
    "new_text = \"The movie was okay.\"\n",
    "predicted_sentiment = predict_sentiment(new_text)\n",
    "print(f\"Predicted sentiment for '{new_text}': {predicted_sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
